{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b06bc0b",
   "metadata": {},
   "source": [
    "## Implementation of the Naive Bayes Classifier and comparison of the prediction with the KNeighborsClassifier from the scikit-learn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc16bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ba391b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'Wind': [2, 2, 0, 0, 1, 1, 0, 2, 0, 2], # 0 No wind 1 Weak wind 2 Strong wind\n",
    "    'Sunny': [0, 0, 1, 1, 0, 1, 0, 1, 0, 0], # 0 Cloudy 1 Sunny\n",
    "    'Temperature': [0, 1, 1, 2, 2, 1, 0, 0, 2, 1], # 0 Cold 1 Warm 2 Hot\n",
    "    'Played Match': [0, 0, 1, 0, 1, 1, 0, 1, 1, 1] # 0 No 1 Yes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "80661891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b0a5c",
   "metadata": {},
   "source": [
    "## Implement Naive Bayes Classifier with Laplace smoothing\n",
    "## Probabilities are calculated this way:\n",
    "## ${Prob}\\{C_{i}\\} = \\frac{|C_{i}| + 1}{|Z| + m}$\n",
    "## ${Prob}\\{x_{k} | C_{i}\\} = \\frac{|C_{i}^{x_{k}}| + 1}{|C_{i}| + |x_{k}|}$, where \n",
    "## $|C_{i}|$ is count of samples that have been classified as $C_{i}$\n",
    "## $|Z|$ is sample count\n",
    "## $|C_{i}^{x_{k}}|$ is count of samples classified as $C_{i}$ that has k-th attribute of value $x_{k}$\n",
    "## $|x_{k}|$ is count of posssible values of k-th feature \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83c3077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifierLaplace:\n",
    "    def __init__(self):\n",
    "        self.class_probabilities = {}  # P(y)\n",
    "        self.feature_probabilities = {}  # P(xi | y) for each feature i\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "        unique_classes_count = len(unique_classes)\n",
    "        total_samples = len(y_train)\n",
    "        self.class_probabilities = {cls: (count + 1) / (total_samples + unique_classes_count) for cls, count in zip(unique_classes, class_counts)}\n",
    "\n",
    "        for feature_index in range(X_train.shape[1]):\n",
    "            unique_values = np.unique(X_train[:, feature_index])\n",
    "            unique_values_count = len(unique_values)\n",
    "            \n",
    "            for feature_value in unique_values:\n",
    "                for cls in unique_classes:\n",
    "                    class_samples_count = len(y_train[y_train == cls])\n",
    "                    feature_class_samples = X_train[(y_train == cls) & (X_train[:, feature_index] == feature_value)]\n",
    "                    self.feature_probabilities[(feature_index, feature_value, cls)] = (feature_class_samples.shape[0] + 1) / (class_samples_count + unique_values_count)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for sample in X_test:\n",
    "            max_prob = float('-inf')\n",
    "            predicted_class = None\n",
    "\n",
    "            for cls, class_prob in self.class_probabilities.items():\n",
    "                total_prob = class_prob\n",
    "                for feature_index, feature_value in enumerate(sample):\n",
    "                    total_prob *= self.feature_probabilities[(feature_index, feature_value, cls)]\n",
    "                    \n",
    "                if total_prob > max_prob:\n",
    "                    max_prob = total_prob\n",
    "                    predicted_class = cls\n",
    "\n",
    "            predictions.append(predicted_class)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1994480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Played Match']\n",
    "X = df.drop(['Played Match'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d0c69",
   "metadata": {},
   "source": [
    "## Instantiate and train Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92acc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb = NaiveBayesClassifierLaplace()\n",
    "model_nb.fit(X.to_numpy().reshape(-1, 3), y.to_numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed805df",
   "metadata": {},
   "source": [
    "## Predictions comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c5715a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pd.DataFrame({\n",
    "    'Wind': [2], \n",
    "    'Sunny': [1],\n",
    "    'Temperature': [1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3eb4518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian classifier prediction: [1]\n",
      "Model 1 neighbors classifier (Euclidean metric) [0]\n",
      "Model 1 neighbors classifier (Manhattan metric) [0]\n",
      "Model 2 neighbors classifier (Euclidean metric) [0]\n",
      "Model 2 neighbors classifier (Manhattan metric) [0]\n",
      "Model 3 neighbors classifier (Euclidean metric) [1]\n",
      "Model 3 neighbors classifier (Manhattan metric) [1]\n",
      "Model 4 neighbors classifier (Euclidean metric) [1]\n",
      "Model 4 neighbors classifier (Manhattan metric) [1]\n",
      "Model 5 neighbors classifier (Euclidean metric) [1]\n",
      "Model 5 neighbors classifier (Manhattan metric) [1]\n"
     ]
    }
   ],
   "source": [
    "print('Bayesian classifier prediction:', model_nb.predict(X_pred.to_numpy().reshape(-1, 3)))\n",
    "for i in range(5):\n",
    "    print(f'Model {i + 1} neighbors classifier (Euclidean metric)',\n",
    "          KNeighborsClassifier(n_neighbors=(i + 1), algorithm='brute', metric='minkowski', p=2)\n",
    "          .fit(X, Y)\n",
    "          .predict(X_pred))\n",
    "    print(f'Model {i + 1} neighbors classifier (Manhattan metric)',\n",
    "          KNeighborsClassifier(n_neighbors=(i + 1), algorithm='brute', metric='minkowski', p=1)\n",
    "          .fit(X, Y)\n",
    "          .predict(X_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aafc08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
